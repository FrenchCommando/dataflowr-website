@def sequence = ["rnn-2"]

# Module 11b - Recurrent Neural Networks practice


**Table of Contents**

\toc


## Theory of RNNs

{{youtube_placeholder rnn-2}}
{{yt_tsp 0 0 Generating the dataset for binary classification of parentheses}}
{{yt_tsp 296 0 Elman network}}
{{yt_tsp 685 0 RNN with gating}}
{{yt_tsp 846 0 LSTM}}
{{yt_tsp 1113 0 Be careful with errors given on the training set!}}

## Notebook

- [notebook](https://github.com/dataflowr/notebooks/blob/master/Module11/11_RNN.ipynb) in [colab](https://colab.research.google.com/github/dataflowr/notebooks/blob/master/Module11/11_RNN.ipynb)

## Practicals

- [notebook](https://github.com/dataflowr/notebooks/blob/master/Module11/11_predicitions_RNN_empty.ipynb) (or opened in [colab](https://colab.research.google.com/github/dataflowr/notebooks/blob/master/Module11/11_predicitions_RNN_empty.ipynb)) for predicting engine failure with RNN [solution](https://forum.dataflowr.com/t/links-to-solution-7-predicting-engine-failure-with-rnn/94) (forum login required)

## References

> Hewitt, J., Hahn, M., Ganguli, S., Liang, P., & Manning, C. D. (2020). RNNs can generate bounded hierarchical languages with optimal memory.[arXiv:2010.07515](https://arxiv.org/abs/2010.07515)


Machine translation

> Sutskever, I., Vinyals, O., & Le, Q. V. (2014). [Sequence to sequence learning with neural networks.](http://papers.neurips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf) In Advances in neural information processing systems (pp. 3104-3112).

> Cho, K., van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., & Bengio, Y. (2014, October). [Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation.](https://arxiv.org/pdf/1406.1078.pdf) In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 1724-1734).

SketchRNN: RNN and VAE

> Ha, D., & Eck, D. (2018, February). [A Neural Representation of Sketch Drawings.](https://arxiv.org/pdf/1704.03477.pdf) In International Conference on Learning Representations.

Generating LaTeX code from handwritten maths

> Zhang, J., Du, J., & Dai, L. (2017, November). [A GRU-based Encoder-Decoder Approach with Attention for Online Handwritten Mathematical Expression Recognition.](https://arxiv.org/pdf/1712.03991.pdf) In 2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR) (Vol. 1, pp. 902-907). IEEE.

Solving mathematical expressions

> Lample, G., & Charton, F. (2019, September). [Deep Learning For Symbolic Mathematics.](https://arxiv.org/pdf/1912.01412.pdf) In International Conference on Learning Representations.
